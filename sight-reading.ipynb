{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tracking position of eyes relative to each other!!! IE. HEIGHT.\n",
    "put the blinking back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764726060.387044 6417924 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1764726060.388469 6418019 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1764726060.393549 6418019 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1764726061.235861 6418024 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "############################################\n",
    "# Configuration\n",
    "############################################\n",
    "BASE_FREQUENCY = 220.0       # Hz, baseline pitch\n",
    "PITCH_RANGE = 600.0          # Hz added/subtracted based on eye direction\n",
    "VOLUME_MIN, VOLUME_MAX = 0.05, 0.8\n",
    "DISTORTION_MAX = 0.8\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "############################################\n",
    "# Shared state between camera + synth threads\n",
    "############################################\n",
    "pitch = BASE_FREQUENCY\n",
    "volume = 0.3\n",
    "distortion = 0.0\n",
    "running = True\n",
    "\n",
    "############################################\n",
    "# Synthesizer thread\n",
    "############################################\n",
    "def synth_loop():\n",
    "    global pitch, volume, distortion, running\n",
    "\n",
    "    phase = 0.0\n",
    "    block_size = 1024\n",
    "    \n",
    "    while running:\n",
    "        t = np.arange(block_size) / SAMPLE_RATE\n",
    "        freq = pitch\n",
    "\n",
    "        # basic sine wave osc\n",
    "        wave = np.sin(2 * np.pi * freq * t + phase)\n",
    "\n",
    "        # distortion (tanh soft clip)\n",
    "        if distortion > 0.01:\n",
    "            wave = np.tanh(wave * (1 + distortion * 10))\n",
    "\n",
    "        wave *= volume\n",
    "\n",
    "        phase += 2 * np.pi * freq * (block_size / SAMPLE_RATE)\n",
    "\n",
    "        sd.play(wave.astype(np.float32), SAMPLE_RATE, blocking=True)\n",
    "\n",
    "    sd.stop()\n",
    "\n",
    "############################################\n",
    "# Eye tracking + mapping to synth parameters\n",
    "############################################\n",
    "mp_face = mp.solutions.face_mesh.FaceMesh(\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def map_value(x, a, b, c, d):\n",
    "    \"\"\"Linear mapping from range [a,b] to [c,d].\"\"\"\n",
    "    return (x - a) / (b - a) * (d - c) + c\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start synth thread\n",
    "threading.Thread(target=synth_loop, daemon=True).start()\n",
    "\n",
    "############################################\n",
    "# Main webcam loop\n",
    "############################################\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = mp_face.process(rgb)\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        if result.multi_face_landmarks:\n",
    "            face = result.multi_face_landmarks[0]\n",
    "\n",
    "            # Eye-related points\n",
    "            left_center = face.landmark[468]      # iris center (L)\n",
    "            nose_base = face.landmark[1]          # stable ref point\n",
    "\n",
    "            # ----- PITCH: horizontal eye position -----\n",
    "            eye_x = left_center.x\n",
    "            pitch = BASE_FREQUENCY + map_value(\n",
    "                eye_x,\n",
    "                0.3, 0.7,          # typical range center-left to center-right\n",
    "                -PITCH_RANGE, PITCH_RANGE\n",
    "            )\n",
    "\n",
    "            # ----- VOLUME: distance to camera -----\n",
    "            dz = abs(left_center.z - nose_base.z)\n",
    "            volume = np.clip(\n",
    "                map_value(dz, 0.015, 0.09, VOLUME_MAX, VOLUME_MIN),\n",
    "                VOLUME_MIN, VOLUME_MAX\n",
    "            )\n",
    "\n",
    "            # ----- DISTORTION: eye openness -----\n",
    "            top_lid = face.landmark[386]\n",
    "            bottom_lid = face.landmark[374]\n",
    "            openness = abs(top_lid.y - bottom_lid.y)\n",
    "\n",
    "            distortion = np.clip(\n",
    "                map_value(openness, 0.01, 0.06, 0.0, DISTORTION_MAX),\n",
    "                0.0, DISTORTION_MAX\n",
    "            )\n",
    "\n",
    "        # Display data on screen\n",
    "        cv2.putText(frame, f\"Pitch: {pitch:.1f} Hz\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Volume: {volume:.2f}\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Distortion: {distortion:.2f}\", (10, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Eye Synth\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    running = False\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
