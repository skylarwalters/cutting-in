{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale sounds\n",
    "this notebook makes you make whale sounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, imports. \n",
    "# cv2 and mediapipe: mouth detectionp=\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "# numpy 4 arrays :P\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "# for the whale sound modulation!\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "from scipy.signal import convolve\n",
    "from pedalboard import Pedalboard, Reverb, Chorus, Delay, PitchShift, LowShelfFilter, Gain, LowpassFilter\n",
    "\n",
    "# to show face\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a whale sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all sounds\n",
    "bases = ['balene', 'hd', 'hump']\n",
    "balene_do_hi, sr = librosa.load('sounds/balene-do (high).wav')\n",
    "balene_re, _ = librosa.load('sounds/balene-re.wav')\n",
    "balene_mi, _ = librosa.load('sounds/balene-mi (3).wav')\n",
    "balene_fa, _ = librosa.load('sounds/balene-fa.wav')\n",
    "balene_sol, _ = librosa.load('sounds/balene-sol (5).wav')\n",
    "balene_la, _ = librosa.load('sounds/balene-la.wav')\n",
    "balene_ti, _ = librosa.load('sounds/balene-ti.wav')\n",
    "balene_do, _ = librosa.load('sounds/balene-low-do.wav')\n",
    "\n",
    "hd_do_hi, sr = librosa.load('sounds/hd-hi.wav')\n",
    "hd_re, _ = librosa.load('sounds/hd-re.wav')\n",
    "hd_mi, _ = librosa.load('sounds/hd-mi.wav')\n",
    "hd_fa, _ = librosa.load('sounds/hd-fa.wav')\n",
    "hd_sol, _ = librosa.load('sounds/hd-so.wav')\n",
    "hd_la, _ = librosa.load('sounds/hd-la.wav')\n",
    "hd_ti, _ = librosa.load('sounds/hd-ti.wav')\n",
    "hd_do, _ = librosa.load('sounds/hd-do.wav')\n",
    "\n",
    "hump_do_hi, sr = librosa.load('sounds/hump-hido.wav')\n",
    "hump_re, _ = librosa.load('sounds/hump-re.wav')\n",
    "hump_mi, _ = librosa.load('sounds/hump-mi.wav')\n",
    "hump_fa, _ = librosa.load('sounds/hump-fa.wav')\n",
    "hump_sol, _ = librosa.load('sounds/hump-sol.wav')\n",
    "hump_la, _ = librosa.load('sounds/hump-la.wav')\n",
    "hump_ti, _ = librosa.load('sounds/hump-ti.wav')\n",
    "hump_do, _ = librosa.load('sounds/hump-do.wav')\n",
    "\n",
    "# make high, mid, and low arrays!\n",
    "hump = [hump_do, hump_re, hump_mi, hump_fa, hump_sol, hump_la, hump_ti, hump_do_hi]\n",
    "hd = [hd_do, hd_re, hd_mi, hd_fa, hd_sol, hd_la, hd_ti, hd_do_hi]\n",
    "balene = [balene_do, balene_re, balene_mi, balene_fa, balene_sol, balene_la, balene_ti, balene_do_hi]\n",
    "\n",
    "hi_hump = [librosa.effects.pitch_shift(sound, sr=sr, n_steps=12) for sound in hump]\n",
    "hi_hd = [librosa.effects.pitch_shift(sound, sr=sr, n_steps=12) for sound in hd]\n",
    "hi_balene = [librosa.effects.pitch_shift(sound, sr=sr, n_steps=12) for sound in balene]\n",
    "\n",
    "lo_hump = [librosa.effects.pitch_shift(sound, sr=sr, n_steps=-12) for sound in hump]\n",
    "lo_hd = [librosa.effects.pitch_shift(sound, sr=sr, n_steps=-12) for sound in hd]\n",
    "lo_balene = [librosa.effects.pitch_shift(sound, sr=sr, n_steps=-12) for sound in balene]\n",
    "\n",
    "#sd.play(hump_do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make out sound sequence. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sounds = [\n",
    "    hump[0],\n",
    "    lo_hd[0],\n",
    "    hump[2],\n",
    "    lo_hump[4],\n",
    "    lo_balene[1],\n",
    "    hd[4],\n",
    "    lo_hd[-1],\n",
    "    lo_hump[-3],\n",
    "    hump[1],\n",
    "    hump[3],\n",
    "    lo_balene[7],\n",
    "    hd[0],\n",
    "    hd[2],\n",
    "    lo_hump[4],\n",
    "    hi_hd[-1],\n",
    "    hi_hd[4],\n",
    "    hd[3],\n",
    "    balene[0],\n",
    "    lo_balene[-1],\n",
    "    hump[3],\n",
    "    hi_hump[-1],\n",
    "    hi_hump[-3],\n",
    "    hd[-1],\n",
    "    hi_hump[-5],\n",
    "    hump[2],\n",
    "    lo_hump[4],\n",
    "    lo_balene[1],\n",
    "    hd[4],\n",
    "    lo_hd[-1],\n",
    "    lo_hump[-3],\n",
    "    hump[1],\n",
    "    hump[3],\n",
    "    lo_balene[7],\n",
    "    lo_hump[-3],\n",
    "    hump[1],\n",
    "    hump[3],\n",
    "    lo_balene[7],\n",
    "    hd[0],\n",
    "    hd[2],\n",
    "    lo_hump[4],\n",
    "    hi_hd[-1],\n",
    "    hi_hd[4],\n",
    "    hd[3],\n",
    "    balene[0],\n",
    "    lo_balene[-1],\n",
    "    hump[3],\n",
    "    hi_hump[-1],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply effects using pedalboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Pedalboard([Reverb(room_size=0.95, damping=1, wet_level=0.8), \n",
    "                    # Delay(delay_seconds=0.5, feedback=1),\n",
    "                    LowShelfFilter(),\n",
    "                    LowpassFilter(),\n",
    "                    Gain(gain_db=3)\n",
    "                    ])\n",
    "\n",
    "sounds = [board(a.astype('float32'), sr) for a in sounds]\n",
    "sounds = [librosa.effects.time_stretch(sound.astype('float32'), rate=0.6) for sound in sounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(sounds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a function to alter the pitch given a number of semitones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Time to play with the mouth processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Distance: determine distance between 2 points\n",
    "'''\n",
    "def distance(a, b):\n",
    "    return np.linalg.norm(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully reset Camera\n"
     ]
    }
   ],
   "source": [
    "!tccutil reset Camera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764772703.705424 6800017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M4 Pro\n",
      "W0000 00:00:1764772703.708112 6801198 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1764772703.714916 6801194 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "OpenCV: not authorized to capture video (status 0), requesting...\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "# create a face mesh from mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "# create a video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Opened:\", cap.isOpened())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the camera and mouth register have been set up, we can begin processing words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset stream!! or it will get MAD!!!\n",
    "stream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "mouth_open = False\n",
    "mouth_open_prev = False\n",
    "current_pitch = 0      \n",
    "\n",
    "# eventually, we will be randomizing the semitone changes + the sound fx\n",
    "step_size = 2 \n",
    "\n",
    "# sound params\n",
    "sound_index = 0\n",
    "fs = 44100      \n",
    "\n",
    "# apply cooldown time --> stops sound from turning evil bc of too much hap\n",
    "cooldown_time = 2  \n",
    "#track lsast sound\n",
    "last_trigger_time = 0 \n",
    "\n",
    "# mixing param\n",
    "buffer_size = 512\n",
    "active_sounds = deque()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add the new sound to the active songs.\n",
    "def trigger_sound(sound_array):\n",
    "    active_sounds.append((sound_array, 0))\n",
    "\n",
    "# gives a limit so we dont have evil soudns\n",
    "def soft_limit(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def audio_callback(outdata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "\n",
    "    mixed = np.zeros(frames, dtype=np.float32)\n",
    "    still_playing = deque()\n",
    "\n",
    "    # mix\n",
    "    for sound_array, idx in active_sounds:\n",
    "        end_idx = min(idx + frames, len(sound_array))\n",
    "        chunk_len = end_idx - idx\n",
    "        if chunk_len > 0:\n",
    "            mixed[:chunk_len] += sound_array[idx:end_idx] * 0.5   # reduce gain\n",
    "        if end_idx < len(sound_array):\n",
    "            still_playing.append((sound_array, end_idx))\n",
    "\n",
    "    # apply soft limiting\n",
    "    mixed = soft_limit(mixed)\n",
    "\n",
    "    outdata[:] = mixed.reshape(-1, 1)\n",
    "\n",
    "    active_sounds.clear()\n",
    "    active_sounds.extend(still_playing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart the stream if it exists!! so everythign doesnt crash.\n",
    "if stream is not None:\n",
    "    try:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# create stream object\n",
    "stream = sd.OutputStream(\n",
    "    channels=1,\n",
    "    #samplerate=fs,\n",
    "    blocksize=buffer_size,\n",
    "    callback=audio_callback,\n",
    ")\n",
    "stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run loooooooop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # create face mesh\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        # find face landmarks\n",
    "        h, w, _ = frame.shape\n",
    "        face = results.multi_face_landmarks[0]\n",
    "        upper = np.array([face.landmark[13].x * w, face.landmark[13].y * h])\n",
    "        lower = np.array([face.landmark[14].x * w, face.landmark[14].y * h])\n",
    "\n",
    "        # create circles on lips\n",
    "        cv2.circle(frame, tuple(upper.astype(int)), 3, (0, 255, 0), -1)\n",
    "        cv2.circle(frame, tuple(lower.astype(int)), 3, (0, 0, 255), -1)\n",
    "\n",
    "        #calculate mouth dsitance and time\n",
    "        mouth_dist = np.linalg.norm(upper - lower)\n",
    "        now = time.time()\n",
    "        \n",
    "        # when mouth is open:\n",
    "        if mouth_dist > 15:\n",
    "            if not mouth_open and (now - last_trigger_time >= cooldown_time):\n",
    "                mouth_open = True\n",
    "                y_sound = sounds[sound_index % len(sounds)]\n",
    "                \n",
    "                # trigger sound!!\n",
    "                trigger_sound(y_sound)\n",
    "                sound_index += 1 # WANT TO MAKE This RANDOM!!!\n",
    "                \n",
    "                last_trigger_time = now \n",
    "                \n",
    "        # close mouth :P\n",
    "        else:\n",
    "            mouth_open = False\n",
    "\n",
    "    False\n",
    "    cv2.imshow(\"cutting in\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()\n",
    "stream.close()\n",
    "cap.release()\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote web_whale_sounds/whale_00.wav\n",
      "wrote web_whale_sounds/whale_01.wav\n",
      "wrote web_whale_sounds/whale_02.wav\n",
      "wrote web_whale_sounds/whale_03.wav\n",
      "wrote web_whale_sounds/whale_04.wav\n",
      "wrote web_whale_sounds/whale_05.wav\n",
      "wrote web_whale_sounds/whale_06.wav\n",
      "wrote web_whale_sounds/whale_07.wav\n",
      "wrote web_whale_sounds/whale_08.wav\n",
      "wrote web_whale_sounds/whale_09.wav\n",
      "wrote web_whale_sounds/whale_10.wav\n",
      "wrote web_whale_sounds/whale_11.wav\n",
      "wrote web_whale_sounds/whale_12.wav\n",
      "wrote web_whale_sounds/whale_13.wav\n",
      "wrote web_whale_sounds/whale_14.wav\n",
      "wrote web_whale_sounds/whale_15.wav\n",
      "wrote web_whale_sounds/whale_16.wav\n",
      "wrote web_whale_sounds/whale_17.wav\n",
      "wrote web_whale_sounds/whale_18.wav\n",
      "wrote web_whale_sounds/whale_19.wav\n",
      "wrote web_whale_sounds/whale_20.wav\n",
      "wrote web_whale_sounds/whale_21.wav\n",
      "wrote web_whale_sounds/whale_22.wav\n",
      "wrote web_whale_sounds/whale_23.wav\n",
      "wrote web_whale_sounds/whale_24.wav\n",
      "wrote web_whale_sounds/whale_25.wav\n",
      "wrote web_whale_sounds/whale_26.wav\n",
      "wrote web_whale_sounds/whale_27.wav\n",
      "wrote web_whale_sounds/whale_28.wav\n",
      "wrote web_whale_sounds/whale_29.wav\n",
      "wrote web_whale_sounds/whale_30.wav\n",
      "wrote web_whale_sounds/whale_31.wav\n",
      "wrote web_whale_sounds/whale_32.wav\n",
      "wrote web_whale_sounds/whale_33.wav\n",
      "wrote web_whale_sounds/whale_34.wav\n",
      "wrote web_whale_sounds/whale_35.wav\n",
      "wrote web_whale_sounds/whale_36.wav\n",
      "wrote web_whale_sounds/whale_37.wav\n",
      "wrote web_whale_sounds/whale_38.wav\n",
      "wrote web_whale_sounds/whale_39.wav\n",
      "wrote web_whale_sounds/whale_40.wav\n",
      "wrote web_whale_sounds/whale_41.wav\n",
      "wrote web_whale_sounds/whale_42.wav\n",
      "wrote web_whale_sounds/whale_43.wav\n",
      "wrote web_whale_sounds/whale_44.wav\n",
      "wrote web_whale_sounds/whale_45.wav\n",
      "wrote web_whale_sounds/whale_46.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf  # pip install soundfile\n",
    "\n",
    "# Folder to save web-ready whale sounds\n",
    "out_dir = \"web_whale_sounds\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 'sounds' is your final processed list of numpy arrays from the notebook\n",
    "for i, sound in enumerate(sounds):\n",
    "    # Ensure mono float32\n",
    "    y = sound.astype(\"float32\").flatten()\n",
    "    filename = os.path.join(out_dir, f\"whale_{i:02d}.wav\")\n",
    "    sf.write(filename, y, sr)  # 'sr' is your sampling rate from librosa.load\n",
    "    print(\"wrote\", filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
